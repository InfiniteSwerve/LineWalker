{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thetis/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/thetis/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model import GPT\n",
    "from data_fetcher import get_padded_image, get_line, extract_patch, get_line_data\n",
    "import einops\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc Type Printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, spine=\"\", is_last_child=True):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    prefix = \"|__\" if indent > 0 else \"\"\n",
    "    print(f\"{spine}{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "    if not isinstance(thing, tuple):\n",
    "        seen.add(current_type)\n",
    "\n",
    "    new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        for idx, item in enumerate(thing):\n",
    "            typeTree(\n",
    "                item, indent + 1, seen, new_spine, is_last_child=(idx == len(thing) - 1)\n",
    "            )\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 1,\n",
    "                set(),\n",
    "                new_spine,\n",
    "                is_last_child=(idx == len(thing) - 1),\n",
    "            )\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            typeTree(sample_item, indent + 1, seen, new_spine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, spine=\"\"):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    prefix = \"|__\" if indent > 0 else \"\"\n",
    "    print(f\"{spine.rstrip()}{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "    if not isinstance(thing, tuple):\n",
    "        seen.add(current_type)\n",
    "\n",
    "    # Add a vertical bar to the spine if not the last child, else add space\n",
    "    new_spine = spine + (\"|  \" if indent > 0 else \"\")\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        for idx, item in enumerate(thing):\n",
    "            is_last_child = idx == len(thing) - 1\n",
    "            next_spine = new_spine if not is_last_child else spine + \"   \"\n",
    "            typeTree(item, indent + 1, seen if not is_last_child else set(), next_spine)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for item in thing:\n",
    "            typeTree(item, indent + 1, set(), new_spine)\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            typeTree(sample_item, indent + 1, seen, new_spine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, spine=\"\"):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    prefix = \"|__\" if indent > 0 else \"\"\n",
    "    print(f\"{spine}{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "    if not isinstance(thing, tuple):\n",
    "        seen.add(current_type)\n",
    "\n",
    "    # Add a vertical bar to the spine if not the last child, else add space\n",
    "    new_spine = spine + (\"|  \" if indent > 0 else \"   \")\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        for idx, item in enumerate(thing):\n",
    "            is_last_child = idx == len(thing) - 1\n",
    "            next_spine = new_spine if not is_last_child else spine + \"   \"\n",
    "            typeTree(item, indent + 1, seen if not is_last_child else set(), next_spine)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for item in thing:\n",
    "            typeTree(item, indent + 1, set(), new_spine)\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            typeTree(sample_item, indent + 1, seen, new_spine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, spine=\"\"):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    print(f\"{spine}|__{current_type}{dtype_str}\")\n",
    "\n",
    "    if not isinstance(thing, tuple):\n",
    "        seen.add(current_type)\n",
    "\n",
    "    new_spine = spine + (\"|  \" if indent > 0 else \"   \")\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        for idx, item in enumerate(thing):\n",
    "            typeTree(\n",
    "                item, indent + 1, seen if idx < len(thing) - 1 else set(), new_spine\n",
    "            )\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            typeTree(item, indent + 1, set(), new_spine)\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            typeTree(sample_item, indent + 1, seen, new_spine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, prefix=\"\"):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    child_prefix = prefix\n",
    "    if indent > 0:\n",
    "        child_prefix = prefix[:-2] + \"| \"\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_prefix = (\n",
    "                child_prefix + \"|__\" if idx < len(thing) - 1 else child_prefix + \"  |__\"\n",
    "            )\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 1,\n",
    "                seen,\n",
    "                new_prefix,\n",
    "            )\n",
    "            local_seen.add(type(item).__name__)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_prefix = (\n",
    "                child_prefix + \"|__\" if idx < len(thing) - 1 else child_prefix + \"  |__\"\n",
    "            )\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 1,\n",
    "                set(),\n",
    "                new_prefix,\n",
    "            )\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            typeTree(\n",
    "                sample_item,\n",
    "                indent + 1,\n",
    "                seen,\n",
    "                child_prefix + \"  |__\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, is_last_child=True):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string based on the current level of indentation and whether the node is the last child\n",
    "    prefix = (\"  \" * indent) + (\"|__\" if indent > 0 else \"\")\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    new_indent = indent + 1\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            typeTree(\n",
    "                item,\n",
    "                new_indent,\n",
    "                seen,\n",
    "                is_last_child=idx == len(thing) - 1,\n",
    "            )\n",
    "            local_seen.add(type(item).__name__)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            typeTree(\n",
    "                item,\n",
    "                new_indent,\n",
    "                set(),\n",
    "                is_last_child=idx == len(thing) - 1,\n",
    "            )\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            typeTree(\n",
    "                sample_item,\n",
    "                new_indent,\n",
    "                seen,\n",
    "                is_last_child=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, prefix=\"\"):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_prefix = prefix + (\"| \" if idx < len(thing) - 1 else \"  \")\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                seen,\n",
    "                new_prefix + \"|__\",\n",
    "            )\n",
    "            local_seen.add(type(item).__name__)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_prefix = prefix + (\"| \" if idx < len(thing) - 1 else \"  \")\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                set(),\n",
    "                new_prefix + \"|__\",\n",
    "            )\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            typeTree(\n",
    "                sample_item,\n",
    "                indent + 2,\n",
    "                seen,\n",
    "                prefix + \"  |__\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Construct new active_branches based on is_last_child\n",
    "    new_active_branches = [not last for last in is_last_child]\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\"| \" if active else \"  \" for active in new_active_branches)\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                seen,\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )\n",
    "            local_seen.add(type(item).__name__)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                set(),\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            new_is_last_child = is_last_child + [True]\n",
    "            typeTree(\n",
    "                sample_item,\n",
    "                indent + 2,\n",
    "                seen,\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches, is_last_child)\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "            new_active_branches = active_branches + [True]\n",
    "            if new_is_last_child[-1]:\n",
    "                new_active_branches[-1] = False\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                seen,\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )\n",
    "            local_seen.add(type(item).__name__)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "            new_active_branches = active_branches + [True]\n",
    "            if new_is_last_child[-1]:\n",
    "                new_active_branches[-1] = False\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                set(),\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            new_is_last_child = is_last_child + [True]\n",
    "            new_active_branches = active_branches + [False]\n",
    "            typeTree(\n",
    "                sample_item,\n",
    "                indent + 2,\n",
    "                seen,\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches, is_last_child)\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            item_type = type(item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "                new_active_branches = active_branches + [idx == len(thing) - 1]\n",
    "                typeTree(\n",
    "                    item,\n",
    "                    indent + 2,\n",
    "                    seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "            new_active_branches = active_branches + [True]\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                set(),  # Reset seen for tuples\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            new_is_last_child = is_last_child + [True]  # Assuming single item for now\n",
    "            new_active_branches = active_branches + [\n",
    "                False\n",
    "            ]  # No more branches to explore\n",
    "            typeTree(\n",
    "                sample_item,\n",
    "                indent + 2,\n",
    "                seen,\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches, is_last_child)\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            item_type = type(item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                typeTree(\n",
    "                    item,\n",
    "                    indent + 2,\n",
    "                    seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "            new_active_branches = active_branches + [True]\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                set(),  # Reset seen for tuples\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            new_is_last_child = is_last_child + [True]  # Assuming single item for now\n",
    "            new_active_branches = active_branches + [\n",
    "                False\n",
    "            ]  # No more branches to explore\n",
    "            typeTree(\n",
    "                sample_item,\n",
    "                indent + 2,\n",
    "                seen,\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches[:-1], is_last_child[:-1])\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, list):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            item_type = type(item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                typeTree(item, indent + 2, seen, new_active_branches, new_is_last_child)\n",
    "                local_seen.add(item_type)\n",
    "\n",
    "    elif isinstance(thing, tuple):\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "            new_active_branches = active_branches + [True]\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                set(),  # Reset seen for tuples\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )\n",
    "\n",
    "    elif hasattr(thing, \"__getitem__\"):\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            new_active_branches = active_branches + [True]\n",
    "            new_is_last_child = is_last_child + [True]  # Assuming single item for now\n",
    "            typeTree(\n",
    "                sample_item, indent + 2, seen, new_active_branches, new_is_last_child\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches[:-1], is_last_child[:-1])\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, (list, tuple)):\n",
    "        for idx, item in enumerate(thing):\n",
    "            new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "            new_active_branches = active_branches + [True]\n",
    "            typeTree(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                seen\n",
    "                if not isinstance(thing, tuple)\n",
    "                else set(),  # Reset seen for tuples\n",
    "                new_active_branches,\n",
    "                new_is_last_child,\n",
    "            )\n",
    "\n",
    "    if hasattr(thing, \"__getitem__\"):\n",
    "        local_seen = set()\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            item_type = type(sample_item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_active_branches = active_branches + [True]\n",
    "                new_is_last_child = is_last_child + [\n",
    "                    True\n",
    "                ]  # Assuming single item for now\n",
    "                typeTree(\n",
    "                    sample_item,\n",
    "                    indent + 2,\n",
    "                    seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches[:-1], is_last_child[:-1])\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, (list, tuple)):\n",
    "        local_seen = (\n",
    "            set() if isinstance(thing, tuple) else set()\n",
    "        )  # Reset local_seen for tuples\n",
    "        for idx, item in enumerate(thing):\n",
    "            item_type = type(item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                typeTree(\n",
    "                    item,\n",
    "                    indent + 2,\n",
    "                    seen\n",
    "                    if not isinstance(thing, tuple)\n",
    "                    else set(),  # Reset seen for tuples\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)\n",
    "\n",
    "    if hasattr(thing, \"__getitem__\"):\n",
    "        local_seen = set()\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            item_type = type(sample_item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_active_branches = active_branches + [True]\n",
    "                new_is_last_child = is_last_child + [\n",
    "                    True\n",
    "                ]  # Assuming single item for now\n",
    "                typeTree(\n",
    "                    sample_item,\n",
    "                    indent + 2,\n",
    "                    seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches[:-1], is_last_child[:-1])\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, (list, tuple)):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            item_type = type(item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                typeTree(\n",
    "                    item,\n",
    "                    indent + 2,\n",
    "                    seen\n",
    "                    if not isinstance(thing, tuple)\n",
    "                    else set(),  # Reset seen if the current thing is a tuple\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)\n",
    "\n",
    "    if hasattr(thing, \"__getitem__\"):\n",
    "        local_seen = set()\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            item_type = type(sample_item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_active_branches = active_branches + [True]\n",
    "                new_is_last_child = is_last_child + [\n",
    "                    True\n",
    "                ]  # Assuming single item for now\n",
    "                typeTree(\n",
    "                    sample_item,\n",
    "                    indent + 2,\n",
    "                    seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches[:-1], is_last_child[:-1])\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen or isinstance(thing, tuple):\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        if current_type != \"tuple\":\n",
    "            seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, (list, tuple)):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            item_type = type(item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                typeTree(\n",
    "                    item,\n",
    "                    indent + 2,\n",
    "                    seen if isinstance(thing, tuple) else local_seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)\n",
    "\n",
    "    if hasattr(thing, \"__getitem__\"):\n",
    "        local_seen = set()\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            item_type = type(sample_item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_active_branches = active_branches + [True]\n",
    "                new_is_last_child = is_last_child + [\n",
    "                    True\n",
    "                ]  # Assuming single item for now\n",
    "                typeTree(\n",
    "                    sample_item,\n",
    "                    indent + 2,\n",
    "                    seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches[:-1], is_last_child[:-1])\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen:\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, (list, tuple)):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            item_type = type(item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                typeTree(\n",
    "                    item, indent + 2, local_seen, new_active_branches, new_is_last_child\n",
    "                )\n",
    "                local_seen.add(item_type)\n",
    "\n",
    "    if hasattr(thing, \"__getitem__\"):\n",
    "        local_seen = set()\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            item_type = type(sample_item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                # Add a new active branch for the child node\n",
    "                new_active_branches = active_branches + [True]\n",
    "                new_is_last_child = is_last_child + [\n",
    "                    True\n",
    "                ]  # Assuming single item for now\n",
    "                typeTree(\n",
    "                    sample_item,\n",
    "                    indent + 2,\n",
    "                    local_seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def __init__(self):\n",
    "        self.lines = []\n",
    "\n",
    "    def traverse(self, thing, indent=0, is_last=True, prefix=\"\"):\n",
    "        # Determine the type of the current object\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type.lower()}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing, indent, is_last, prefix)\n",
    "\n",
    "    def default_handler(self, thing, indent, is_last, prefix):\n",
    "        dtype_str = \"\"\n",
    "        if hasattr(thing, \"dtype\"):\n",
    "            dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "        new_prefix = prefix + (\"    \" if is_last else \"|   \")\n",
    "\n",
    "        # Print the current object type\n",
    "        self.lines.append(\n",
    "            f\"{prefix}|__{type(thing).__name__}{dtype_str}\"\n",
    "            if indent\n",
    "            else f\"{type(thing).__name__}{dtype_str}\"\n",
    "        )\n",
    "\n",
    "        if isinstance(thing, str):\n",
    "            return\n",
    "        elif hasattr(thing, \"__getitem__\"):\n",
    "            items = list(thing)\n",
    "            for i, item in enumerate(items):\n",
    "                self.traverse(item, indent + 1, i == len(items) - 1, new_prefix)\n",
    "\n",
    "    def handle_tensor(self, thing, indent, is_last, prefix):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "        new_prefix = prefix + (\"    \" if is_last else \"|   \")\n",
    "\n",
    "        # Print the current object type\n",
    "        self.lines.append(\n",
    "            f\"{prefix}|__{type(thing).__name__}{dtype_str}\"\n",
    "            if indent\n",
    "            else f\"{type(thing).__name__}{dtype_str}\"\n",
    "        )\n",
    "\n",
    "        for i in range(thing.dim()):\n",
    "            dim_str = f\"dim_{i} ({thing.size(i)})\"\n",
    "            self.lines.append(f\"{new_prefix}|__{dim_str}\")\n",
    "\n",
    "    def display(self):\n",
    "        for line in self.lines:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def __init__(self):\n",
    "        self.lines = []\n",
    "\n",
    "    def traverse(self, thing, is_last=True, prefix=\"\"):\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type.lower()}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing, is_last, prefix)\n",
    "\n",
    "    def default_handler(self, thing, is_last, prefix):\n",
    "        current_type = type(thing).__name__\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\" if hasattr(thing, \"dtype\") else \"\"\n",
    "        new_prefix = prefix + (\"|   \" if not is_last else \"    \")\n",
    "        self.lines.append(f\"{prefix}|__{current_type}{dtype_str}\")\n",
    "\n",
    "        if hasattr(thing, \"__getitem__\") and not isinstance(thing, str):\n",
    "            items = list(thing)[\n",
    "                :1\n",
    "            ]  # Consider only the first item in a homogeneous list\n",
    "            for i, item in enumerate(items):\n",
    "                self.traverse(item, i == len(items) - 1, new_prefix)\n",
    "\n",
    "    def handle_tensor(self, thing, is_last, prefix):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "        new_prefix = prefix + (\"|   \" if not is_last else \"    \")\n",
    "        self.lines.append(f\"{prefix}|__Tensor{dtype_str}\")\n",
    "\n",
    "        for i in range(thing.dim()):\n",
    "            dim_str = f\"dim_{i} ({thing.size(i)})\"\n",
    "            self.lines.append(f\"{new_prefix}|__{dim_str}\")\n",
    "\n",
    "    def display(self):\n",
    "        for line in self.lines:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def traverse(\n",
    "        self, thing, indent=0, seen=None, active_branches=None, is_last_child=None\n",
    "    ):\n",
    "        print(\n",
    "            f\"Traverse was called with active_branches: {active_branches}, is_last_child: {is_last_child}\"\n",
    "        )\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "        if active_branches is None:\n",
    "            active_branches = []\n",
    "        if is_last_child is None:\n",
    "            is_last_child = []\n",
    "\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing, indent, seen, active_branches.copy(), is_last_child.copy())\n",
    "\n",
    "    def default_handler(self, thing, indent, seen, active_branches, is_last_child):\n",
    "        current_type = type(thing).__name__\n",
    "        dtype_str = \"\"\n",
    "        if hasattr(thing, \"dtype\"):\n",
    "            dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "        prefix = \"\".join(\n",
    "            \"| \" if active and not last else \"  \"\n",
    "            for active, last in zip(active_branches, is_last_child)\n",
    "        )\n",
    "        prefix += \"|__\" if indent > 0 else \"\"\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "        if hasattr(thing, \"__getitem__\"):\n",
    "            try:\n",
    "                sample_item = thing[0]\n",
    "            except (IndexError, KeyError, TypeError):\n",
    "                sample_item = None\n",
    "\n",
    "            if sample_item is not None:\n",
    "                new_is_last_child = is_last_child + [True]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                print(f\"Calling self.traverse in default_handler\")\n",
    "                self.traverse(\n",
    "                    sample_item,\n",
    "                    indent + 2,\n",
    "                    seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "\n",
    "    def handle_list(self, thing, indent, seen, active_branches, is_last_child):\n",
    "        print(\n",
    "            f\"Handling a list with active_branches: {active_branches}, is_last_child: {is_last_child}\"\n",
    "        )\n",
    "\n",
    "        self.default_handler(thing, indent, seen, active_branches, is_last_child)\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            is_last = idx == len(thing) - 1\n",
    "            print(f\"Calling self.traverse in handle_list\")\n",
    "            self.traverse(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                local_seen,\n",
    "                active_branches + [True],\n",
    "                is_last_child + [is_last],\n",
    "            )\n",
    "\n",
    "    def handle_tuple(self, thing, indent, seen, active_branches, is_last_child):\n",
    "        print(\n",
    "            f\"Handling a tuple with active_branches: {active_branches}, is_last_child: {is_last_child}\"\n",
    "        )\n",
    "\n",
    "        self.default_handler(thing, indent, seen, active_branches, is_last_child)\n",
    "        for idx, item in enumerate(thing):\n",
    "            is_last = idx == len(thing) - 1\n",
    "            print(f\"Calling self.traverse in handle_tuple\")\n",
    "            self.traverse(\n",
    "                item,\n",
    "                indent + 2,\n",
    "                seen,\n",
    "                active_branches + [True],\n",
    "                is_last_child + [is_last],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def traverse(\n",
    "        self, thing, indent=0, seen=None, active_branches=None, is_last_child=None\n",
    "    ):\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "        if active_branches is None:\n",
    "            active_branches = []\n",
    "        if is_last_child is None:\n",
    "            is_last_child = []\n",
    "\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing, indent, seen, active_branches.copy(), is_last_child.copy())\n",
    "\n",
    "    def default_handler(self, thing, indent, seen, active_branches, is_last_child):\n",
    "        current_type = type(thing).__name__\n",
    "        dtype_str = \"\"\n",
    "        if hasattr(thing, \"dtype\"):\n",
    "            dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "        prefix = \"\".join(\n",
    "            \"| \" if active and not last else \"  \"\n",
    "            for active, last in zip(active_branches, is_last_child)\n",
    "        )\n",
    "        prefix += \"|__\" if active_branches else \"\"\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "        if hasattr(thing, \"__getitem__\"):\n",
    "            try:\n",
    "                sample_item = thing[0]\n",
    "            except (IndexError, KeyError, TypeError):\n",
    "                sample_item = None\n",
    "\n",
    "            if sample_item is not None:\n",
    "                new_is_last_child = is_last_child + [True]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                self.traverse(\n",
    "                    sample_item,\n",
    "                    indent + 2,\n",
    "                    seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "\n",
    "    def handle_list(self, thing, indent, seen, active_branches, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, active_branches, is_last_child)\n",
    "        local_seen = set()\n",
    "        new_is_last_child = is_last_child + [False] * (len(thing) - 1) + [True]\n",
    "        new_active_branches = active_branches + [True]\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item, indent + 2, local_seen, new_active_branches, new_is_last_child\n",
    "            )\n",
    "\n",
    "    def handle_tuple(self, thing, indent, seen, active_branches, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, active_branches, is_last_child)\n",
    "        new_is_last_child = is_last_child + [False] * (len(thing) - 1) + [True]\n",
    "        new_active_branches = active_branches + [True]\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item, indent + 2, seen, new_active_branches, new_is_last_child\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def traverse(\n",
    "        self, thing, indent=0, seen=None, active_branches=None, is_last_child=None\n",
    "    ):\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "        if active_branches is None:\n",
    "            active_branches = []\n",
    "        if is_last_child is None:\n",
    "            is_last_child = []\n",
    "\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing, indent, seen, active_branches, is_last_child)\n",
    "\n",
    "    def default_handler(self, thing, indent, seen, active_branches, is_last_child):\n",
    "        current_type = type(thing).__name__\n",
    "        dtype_str = \"\"\n",
    "        if hasattr(thing, \"dtype\"):\n",
    "            dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "        prefix = \"\".join(\n",
    "            \"| \" if active and not last else \"  \"\n",
    "            for active, last in zip(active_branches[:-1], is_last_child[:-1])\n",
    "        )\n",
    "        prefix += \"|__\" if active_branches else \"\"\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "        if hasattr(thing, \"__getitem__\"):\n",
    "            try:\n",
    "                sample_item = thing[0]\n",
    "            except (IndexError, KeyError, TypeError):\n",
    "                sample_item = None\n",
    "\n",
    "            if sample_item is not None:\n",
    "                new_is_last_child = is_last_child + [True]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                self.traverse(\n",
    "                    sample_item,\n",
    "                    indent + 2,\n",
    "                    seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "\n",
    "    def handle_list(self, thing, indent, seen, active_branches, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, active_branches, is_last_child)\n",
    "        local_seen = set()\n",
    "        new_is_last_child = is_last_child + [False] * (len(thing) - 1) + [True]\n",
    "        new_active_branches = active_branches + [True]\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item, indent + 2, local_seen, new_active_branches, new_is_last_child\n",
    "            )\n",
    "\n",
    "    def handle_tuple(self, thing, indent, seen, active_branches, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, active_branches, is_last_child)\n",
    "        new_is_last_child = is_last_child + [False] * (len(thing) - 1) + [True]\n",
    "        new_active_branches = active_branches + [True]\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item, indent + 2, seen, new_active_branches, new_is_last_child\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def traverse(self, thing, indent=0, seen=None, spine=\"\", is_last_child=True):\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing, indent, seen, spine, is_last_child)\n",
    "\n",
    "    def default_handler(self, thing, indent, seen, spine, is_last_child):\n",
    "        current_type = type(thing).__name__\n",
    "        dtype_str = \"\"\n",
    "        if hasattr(thing, \"dtype\"):\n",
    "            dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "        prefix = \"|__\" if indent > 0 else \"\"\n",
    "        print(f\"{spine}{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "\n",
    "        if hasattr(thing, \"__getitem__\"):\n",
    "            try:\n",
    "                sample_item = thing[0]\n",
    "            except (IndexError, KeyError, TypeError):\n",
    "                sample_item = None\n",
    "\n",
    "            if sample_item is not None:\n",
    "                self.traverse(sample_item, indent + 1, seen, new_spine)\n",
    "\n",
    "    def handle_list(self, thing, indent, seen, spine, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, spine, is_last_child)\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item, indent + 1, seen, new_spine, is_last_child=(idx == len(thing) - 1)\n",
    "            )\n",
    "\n",
    "    def handle_tuple(self, thing, indent, seen, spine, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, spine, is_last_child)\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item, indent + 1, None, new_spine, is_last_child=(idx == len(thing) - 1)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def traverse(self, thing, indent=0, seen=None, spine=\"\", is_last_child=True):\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing, indent, seen, spine, is_last_child)\n",
    "\n",
    "    def default_handler(self, thing, indent, seen, spine, is_last_child):\n",
    "        current_type = type(thing).__name__\n",
    "        dtype_str = \"\"\n",
    "        if hasattr(thing, \"dtype\"):\n",
    "            dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "        prefix = \"|__\" if indent > 0 else \"\"\n",
    "        print(f\"{spine}{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "\n",
    "        if hasattr(thing, \"__getitem__\"):\n",
    "            try:\n",
    "                sample_item = thing[0]\n",
    "            except (IndexError, KeyError, TypeError):\n",
    "                sample_item = None\n",
    "\n",
    "            if sample_item is not None:\n",
    "                self.traverse(sample_item, indent + 1, seen, new_spine)\n",
    "\n",
    "    def handle_list(self, thing, indent, seen, spine, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, spine, is_last_child)\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item, indent + 1, seen, new_spine, is_last_child=(idx == len(thing) - 1)\n",
    "            )\n",
    "\n",
    "    def handle_tuple(self, thing, indent, seen, spine, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, spine, is_last_child)\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item, indent + 1, seen, new_spine, is_last_child=(idx == len(thing) - 1)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def traverse(self, thing, indent=0, seen=None, spine=\"\", is_last_child=True):\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing, indent, seen, spine, is_last_child)\n",
    "\n",
    "    def default_handler(self, thing, indent, seen, spine, is_last_child):\n",
    "        current_type = type(thing).__name__\n",
    "        dtype_str = \"\"\n",
    "        if hasattr(thing, \"dtype\"):\n",
    "            dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "        prefix = \"|__\" if indent > 0 else \"\"\n",
    "        print(f\"{spine}{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "        if hasattr(thing, \"__getitem__\"):\n",
    "            try:\n",
    "                sample_item = thing[0]\n",
    "            except (IndexError, KeyError, TypeError):\n",
    "                sample_item = None\n",
    "\n",
    "            if sample_item is not None:\n",
    "                self.traverse(sample_item, indent + 1, seen, new_spine)\n",
    "\n",
    "    def handle_list(self, thing, indent, seen, spine, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, spine, is_last_child)\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item, indent + 1, seen, new_spine, is_last_child=(idx == len(thing) - 1)\n",
    "            )\n",
    "\n",
    "    def handle_tuple(self, thing, indent, seen, spine, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, spine, is_last_child)\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item,\n",
    "                indent + 1,\n",
    "                set(),\n",
    "                new_spine,\n",
    "                is_last_child=(idx == len(thing) - 1),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def traverse(self, thing, indent=0, seen=None, spine=\"\", is_last_child=True):\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing, indent, seen, spine, is_last_child)\n",
    "\n",
    "    def default_handler(self, thing, indent, seen, spine, is_last_child):\n",
    "        current_type = type(thing).__name__\n",
    "        dtype_str = \"\"\n",
    "        if hasattr(thing, \"dtype\"):\n",
    "            dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "        prefix = \"|__\" if indent > 0 else \"\"\n",
    "        print(f\"{spine}{prefix}{current_type}{dtype_str}\")\n",
    "\n",
    "        if not isinstance(thing, tuple):\n",
    "            seen.add(current_type)\n",
    "\n",
    "        new_spine = spine + (\"   \" if is_last_child else \"|  \")\n",
    "\n",
    "        if hasattr(thing, \"__getitem__\"):\n",
    "            try:\n",
    "                sample_item = thing[0]\n",
    "            except (IndexError, KeyError, TypeError):\n",
    "                sample_item = None\n",
    "\n",
    "            if sample_item is not None:\n",
    "                self.traverse(sample_item, indent + 1, seen, new_spine)\n",
    "\n",
    "    def handle_list(self, thing, indent, seen, spine, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, spine, is_last_child)\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item,\n",
    "                indent + 1,\n",
    "                seen,\n",
    "                spine + \"|  \",\n",
    "                is_last_child=(idx == len(thing) - 1),\n",
    "            )\n",
    "\n",
    "    def handle_tuple(self, thing, indent, seen, spine, is_last_child):\n",
    "        self.default_handler(thing, indent, seen, spine, is_last_child)\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item,\n",
    "                indent + 1,\n",
    "                set(),\n",
    "                spine + \"|  \",\n",
    "                is_last_child=(idx == len(thing) - 1),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeTree:\n",
    "    def __init__(self):\n",
    "        self.indent = 0\n",
    "        self.seen = set()\n",
    "        self.spine = \"\"\n",
    "        self.is_last_child = True\n",
    "\n",
    "    def traverse(self, thing, indent=0, seen=None, spine=\"\", is_last_child=True):\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "\n",
    "        self.indent = indent\n",
    "        self.seen = seen\n",
    "        self.spine = spine\n",
    "        self.is_last_child = is_last_child\n",
    "\n",
    "        current_type = type(thing).__name__\n",
    "        method_name = f\"handle_{current_type}\"\n",
    "        handler = getattr(self, method_name, self.default_handler)\n",
    "        handler(thing)\n",
    "\n",
    "    def default_handler(self, thing):\n",
    "        dtype_str = \"\"\n",
    "        if hasattr(thing, \"dtype\"):\n",
    "            dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "        prefix = \"|__\" if self.indent > 0 else \"\"\n",
    "        print(f\"{self.spine}{prefix}{type(thing).__name__}{dtype_str}\")\n",
    "\n",
    "        if not isinstance(thing, tuple):\n",
    "            self.seen.add(type(thing).__name__)\n",
    "\n",
    "        new_spine = self.spine + (\"   \" if self.is_last_child else \"|  \")\n",
    "        if hasattr(thing, \"__getitem__\"):\n",
    "            try:\n",
    "                sample_item = thing[0]\n",
    "            except (IndexError, KeyError, TypeError):\n",
    "                sample_item = None\n",
    "            if sample_item is not None:\n",
    "                self.traverse(sample_item, self.indent + 1, self.seen, new_spine)\n",
    "\n",
    "    def handle_list(self, thing):\n",
    "        self.default_handler(thing)\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item,\n",
    "                self.indent + 1,\n",
    "                self.seen,\n",
    "                self.spine + \"|  \",\n",
    "                is_last_child=(idx == len(thing) - 1),\n",
    "            )\n",
    "\n",
    "    def handle_tuple(self, thing):\n",
    "        self.default_handler(thing)\n",
    "        for idx, item in enumerate(thing):\n",
    "            self.traverse(\n",
    "                item,\n",
    "                self.indent + 1,\n",
    "                set(),\n",
    "                self.spine + \"|  \",\n",
    "                is_last_child=(idx == len(thing) - 1),\n",
    "            )\n",
    "\n",
    "    # Add methods for any other types you wish to handle specially.\n",
    "    # For example:\n",
    "    # def handle_Subset(self, thing):\n",
    "    #     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.10/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (122880000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image = get_padded_image(\"./juneau2k.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = get_line(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1372, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumps = (first_line[1:] - first_line[:-1]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., -0.],\n",
       "        [7., 0.],\n",
       "        [7., 0.],\n",
       "        ...,\n",
       "        [2., 0.],\n",
       "        [3., 1.],\n",
       "        [2., -0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "jumps tells us the diff between point n+1 and n. Starting at 0. \n",
    "Since we're utilizing the first 2 data points, we use the 0th and 1st points, and our target is the 2nd - 1st points. \n",
    "\"\"\"\n",
    "input_points = list(zip(first_line[:-2], first_line[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumps = (first_line[1:] - first_line[:-1]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_points = jumps[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = get_line(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1372, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = get_line_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n",
      "   |__Subset\n",
      "   |  |__tuple\n",
      "   |     |__Tensor (dtype: torch.float64)\n",
      "   |     |  |__Tensor (dtype: torch.float64)\n",
      "   |     |     |__Tensor (dtype: torch.float64)\n",
      "   |     |__Tensor (dtype: torch.float64)\n",
      "   |        |__Tensor (dtype: torch.float64)\n",
      "   |__Subset\n",
      "      |__tuple\n",
      "         |__Tensor (dtype: torch.float64)\n",
      "         |  |__Tensor (dtype: torch.float64)\n",
      "         |     |__Tensor (dtype: torch.float64)\n",
      "         |__Tensor (dtype: torch.float64)\n",
      "            |__Tensor (dtype: torch.float64)\n"
     ]
    }
   ],
   "source": [
    "torch_types = {\n",
    "    name: cls for name, cls in torch.__dict__.items() if isinstance(cls, type)\n",
    "}\n",
    "\n",
    "typeTree(get_line_data(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n",
      "   |__Subset\n",
      "   |  |__tuple\n",
      "   |     |__Tensor (dtype: torch.float64)\n",
      "   |     |  |__Tensor (dtype: torch.float64)\n",
      "   |     |     |__Tensor (dtype: torch.float64)\n",
      "   |     |__Tensor (dtype: torch.float64)\n",
      "   |        |__Tensor (dtype: torch.float64)\n",
      "   |__Subset\n",
      "      |__tuple\n",
      "         |__Tensor (dtype: torch.float64)\n",
      "         |  |__Tensor (dtype: torch.float64)\n",
      "         |     |__Tensor (dtype: torch.float64)\n",
      "         |__Tensor (dtype: torch.float64)\n",
      "            |__Tensor (dtype: torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "list of subsets of tuples of tensors\n",
    "but what I want is a list of \n",
    "\"\"\"\n",
    "d = get_line_data(0)\n",
    "typeTree(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = get_line(0)\n",
    "\n",
    "jumps = (line[1:] - line[:-1]).round()\n",
    "output = list(zip(torch.stack([line[:-2], line[1:-1]]), jumps[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = torch.randn(10, 2)\n",
    "jumps = (line[1:] - line[:-1]).round()\n",
    "s = torch.stack([line[:-2], line[1:-1]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list(zip(s, jumps[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9962, -0.5673],\n",
       "         [ 1.5197,  0.8453]],\n",
       "\n",
       "        [[ 1.5197,  0.8453],\n",
       "         [ 0.6859, -0.0692]],\n",
       "\n",
       "        [[ 0.6859, -0.0692],\n",
       "         [-1.2299, -1.0222]],\n",
       "\n",
       "        [[-1.2299, -1.0222],\n",
       "         [ 0.0463,  1.3502]],\n",
       "\n",
       "        [[ 0.0463,  1.3502],\n",
       "         [-0.1309, -1.5546]],\n",
       "\n",
       "        [[-0.1309, -1.5546],\n",
       "         [-1.9320, -0.5457]],\n",
       "\n",
       "        [[-1.9320, -0.5457],\n",
       "         [ 1.7011, -0.4821]],\n",
       "\n",
       "        [[ 1.7011, -0.4821],\n",
       "         [-0.4964, -2.1380]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9962, -0.5673],\n",
       "         [ 1.5197,  0.8453]]),\n",
       " tensor([-1., -1.]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n",
      "   |__tuple\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |  |  |__Tensor (dtype: torch.float32)\n",
      "   |  |     |__Tensor (dtype: torch.float32)\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |     |__Tensor (dtype: torch.float32)\n",
      "   |__tuple\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |  |  |__Tensor (dtype: torch.float32)\n",
      "   |  |     |__Tensor (dtype: torch.float32)\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |     |__Tensor (dtype: torch.float32)\n",
      "   |__tuple\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |  |  |__Tensor (dtype: torch.float32)\n",
      "   |  |     |__Tensor (dtype: torch.float32)\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |     |__Tensor (dtype: torch.float32)\n",
      "   |__tuple\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |  |  |__Tensor (dtype: torch.float32)\n",
      "   |  |     |__Tensor (dtype: torch.float32)\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |     |__Tensor (dtype: torch.float32)\n",
      "   |__tuple\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |  |  |__Tensor (dtype: torch.float32)\n",
      "   |  |     |__Tensor (dtype: torch.float32)\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |     |__Tensor (dtype: torch.float32)\n",
      "   |__tuple\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |  |  |__Tensor (dtype: torch.float32)\n",
      "   |  |     |__Tensor (dtype: torch.float32)\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |     |__Tensor (dtype: torch.float32)\n",
      "   |__tuple\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |  |  |__Tensor (dtype: torch.float32)\n",
      "   |  |     |__Tensor (dtype: torch.float32)\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |     |__Tensor (dtype: torch.float32)\n",
      "   |__tuple\n",
      "      |__Tensor (dtype: torch.float32)\n",
      "      |  |__Tensor (dtype: torch.float32)\n",
      "      |     |__Tensor (dtype: torch.float32)\n",
      "      |__Tensor (dtype: torch.float32)\n",
      "         |__Tensor (dtype: torch.float32)\n"
     ]
    }
   ],
   "source": [
    "line = torch.randn(10, 2)\n",
    "jumps = (line[1:] - line[:-1]).round()\n",
    "output = list(zip(torch.stack([line[:-2], line[1:-1]], dim=1), jumps[1:]))\n",
    "typeTree(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.4849, -0.5678],\n",
       "         [-0.1166,  0.9049]]),\n",
       " tensor([ 1., -1.]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 1., -1.]), tensor([ 1., -1.])),\n",
       " (tensor([-2.,  1.]), tensor([-2.,  1.])),\n",
       " (tensor([1., 1.]), tensor([1., 1.])),\n",
       " (tensor([ 2., -3.]), tensor([ 2., -3.])),\n",
       " (tensor([-1.,  1.]), tensor([-1.,  1.])),\n",
       " (tensor([-1.,  2.]), tensor([-1.,  2.])),\n",
       " (tensor([-2., -1.]), tensor([-2., -1.])),\n",
       " (tensor([2., 0.]), tensor([2., 0.]))]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(jumps[1:], jumps[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.4849, -0.5678],\n",
       "         [-0.1166,  0.9049]]),\n",
       " tensor([ 1., -1.]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3)\n",
    "b = torch.randn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TypeTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple\n",
      "   |__tuple\n",
      "   |  |__tuple\n",
      "   |  |  |__int\n",
      "   |  |  |__int\n",
      "   |  |__tuple\n",
      "   |     |__int\n",
      "   |     |__int\n",
      "   |__tuple\n",
      "      |__int\n",
      "      |__int\n"
     ]
    }
   ],
   "source": [
    "thing = (((1, 2), (1, 2)), (1, 2))\n",
    "typeTree((((1, 2), (1, 2)), (1, 2)))\n",
    "t.traverse(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor (dtype: torch.float32)\n",
      "   |__Tensor (dtype: torch.float32)\n",
      "      |__Tensor (dtype: torch.float32)\n"
     ]
    }
   ],
   "source": [
    "typeTree(a)\n",
    "t.traverse(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple\n",
      "   |__Tensor (dtype: torch.float32)\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |     |__Tensor (dtype: torch.float32)\n",
      "   |__Tensor (dtype: torch.float32)\n",
      "   |  |__Tensor (dtype: torch.float32)\n",
      "   |__Tensor (dtype: torch.int64)\n",
      "|__tuple\n",
      "    |__Tensor (dtype: torch.float32)\n",
      "        |__dim_0 (2)\n",
      "        |__dim_1 (3)\n"
     ]
    }
   ],
   "source": [
    "typeTree((a, b, c))\n",
    "t = TypeTree()\n",
    "t.traverse((a, b, c))\n",
    "t.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n",
      "   |__tuple\n",
      "      |__list\n",
      "      |  |__tuple\n",
      "      |     |__int\n",
      "      |     |__int\n",
      "      |__int\n"
     ]
    }
   ],
   "source": [
    "typeTree([([(1, 2)], 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n",
      "|__tuple\n",
      "| |__Tensor (dtype: torch.float32)\n",
      "| | |__Tensor (dtype: torch.float32)\n",
      "| |   |__Tensor (dtype: torch.float32)\n",
      "| |__Tensor (dtype: torch.float32)\n",
      "|   |__Tensor (dtype: torch.float32)\n",
      "|     |__Tensor (dtype: torch.float32)\n",
      "|__tuple\n",
      "  |__Tensor (dtype: torch.float32)\n",
      "  | |__Tensor (dtype: torch.float32)\n",
      "  |   |__Tensor (dtype: torch.float32)\n",
      "  |__Tensor (dtype: torch.float32)\n",
      "    |__Tensor (dtype: torch.float32)\n",
      "      |__Tensor (dtype: torch.float32)\n"
     ]
    }
   ],
   "source": [
    "typeTree(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 1], [2, 2], [3, 3]]\n",
    "b = [[4, 4], [5, 5], [6, 6]]\n",
    "c = [[7, 7], [8, 8], [9, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 1], [4, 4]), ([2, 2], [5, 5]), ([3, 3], [6, 6])]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.4849, -0.5678],\n",
       "         [-0.1166,  0.9049]]),\n",
       " tensor([ 1., -1.]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor (dtype: torch.float32)\n",
      "|__Tensor (dtype: torch.float32)\n",
      "  |__Tensor (dtype: torch.float32)\n",
      "Tensor (dtype: torch.float32)\n",
      "|__Tensor (dtype: torch.float32)\n",
      "  |__Tensor (dtype: torch.float32)\n",
      "list\n",
      "|__tuple\n",
      "| |__Tensor (dtype: torch.float32)\n",
      "| | |__Tensor (dtype: torch.float32)\n",
      "| |   |__Tensor (dtype: torch.float32)\n",
      "| |__Tensor (dtype: torch.float32)\n",
      "|   |__Tensor (dtype: torch.float32)\n",
      "|     |__Tensor (dtype: torch.float32)\n",
      "|__tuple\n",
      "  |__Tensor (dtype: torch.float32)\n",
      "  | |__Tensor (dtype: torch.float32)\n",
      "  |   |__Tensor (dtype: torch.float32)\n",
      "  |__Tensor (dtype: torch.float32)\n",
      "    |__Tensor (dtype: torch.float32)\n",
      "      |__Tensor (dtype: torch.float32)\n"
     ]
    }
   ],
   "source": [
    "typeTree(line)\n",
    "typeTree(jumps)\n",
    "typeTree(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(num_layers=3, d_model=128, num_heads=8, d_hidden=512, input_dim=912)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.functional.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.10/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (122880000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[5715.5925, 2466.7177],\n",
      "        [5719.2166, 2464.7662]], dtype=torch.float64), tensor([ 2., -3.], dtype=torch.float64)), (tensor([[7281.2525, 3186.4082],\n",
      "        [7285.3080, 3188.1287]], dtype=torch.float64), tensor([4., 2.], dtype=torch.float64)), (tensor([[4531.2521, 2481.4929],\n",
      "        [4530.0441, 2479.1697]], dtype=torch.float64), tensor([-2., -3.], dtype=torch.float64)), (tensor([[8046.6384, 3692.7818],\n",
      "        [8049.9837, 3692.7818]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[7722.0750, 3468.9426],\n",
      "        [7724.1642, 3470.2945]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[6716.9271, 2985.1439],\n",
      "        [6722.7216, 2985.7092]], dtype=torch.float64), tensor([5., -0.], dtype=torch.float64)), (tensor([[4827.4069, 2440.3267],\n",
      "        [4831.0310, 2438.8399]], dtype=torch.float64), tensor([ 4., -1.], dtype=torch.float64)), (tensor([[4571.3961, 2479.0768],\n",
      "        [4574.7414, 2479.4485]], dtype=torch.float64), tensor([1., 1.], dtype=torch.float64)), (tensor([[8244.1059, 3827.9890],\n",
      "        [8245.9644, 3829.3829]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[5816.7888, 2493.2945],\n",
      "        [5820.8775, 2493.7591]], dtype=torch.float64), tensor([6., 0.], dtype=torch.float64)), (tensor([[4523.4463, 2461.1421],\n",
      "        [4523.6322, 2456.4029]], dtype=torch.float64), tensor([ 1., -4.], dtype=torch.float64)), (tensor([[5896.6121, 2544.4966],\n",
      "        [5896.7051, 2548.7712]], dtype=torch.float64), tensor([1., 3.], dtype=torch.float64)), (tensor([[4866.5287, 2428.6180],\n",
      "        [4869.9669, 2427.1312]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[7744.9334, 3484.9189],\n",
      "        [7747.8828, 3486.3937]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[6489.6891, 2959.1763],\n",
      "        [6492.7614, 2958.5618]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[4633.7366, 2541.0893],\n",
      "        [4635.2113, 2543.7929]], dtype=torch.float64), tensor([1., 1.], dtype=torch.float64)), (tensor([[8150.9942, 3759.0380],\n",
      "        [8152.1093, 3761.5470]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[7036.5695, 3050.1182],\n",
      "        [7040.2564, 3051.9616]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[8139.8430, 3741.7538],\n",
      "        [8141.3299, 3743.4264]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[5037.4194, 2420.9981],\n",
      "        [5041.2294, 2421.4628]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[8123.2093, 3724.2837],\n",
      "        [8123.8598, 3725.5847]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[6419.2705, 2949.3448],\n",
      "        [6422.3429, 2951.6797]], dtype=torch.float64), tensor([5., 2.], dtype=torch.float64)), (tensor([[7089.0455, 3075.0658],\n",
      "        [7092.4865, 3077.2779]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[4529.3936, 2496.9186],\n",
      "        [4530.6945, 2493.4803]], dtype=torch.float64), tensor([ 1., -4.], dtype=torch.float64)), (tensor([[7628.4294, 3415.9751],\n",
      "        [7632.3620, 3416.7125]], dtype=torch.float64), tensor([5., 1.], dtype=torch.float64)), (tensor([[4971.2714, 2420.0782],\n",
      "        [4974.6442, 2419.3755]], dtype=torch.float64), tensor([3., -0.], dtype=torch.float64)), (tensor([[6753.6726, 2980.0561],\n",
      "        [6758.3364, 2981.6107]], dtype=torch.float64), tensor([6., 1.], dtype=torch.float64)), (tensor([[7208.4989, 3130.3683],\n",
      "        [7212.6773, 3130.3683]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[8275.0502, 3863.5796],\n",
      "        [8277.0946, 3864.7876]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[5108.9723, 2419.8830],\n",
      "        [5113.2469, 2419.5113]], dtype=torch.float64), tensor([5., -0.], dtype=torch.float64)), (tensor([[6862.4281, 2970.2368],\n",
      "        [6866.4836, 2969.6223]], dtype=torch.float64), tensor([7., 0.], dtype=torch.float64)), (tensor([[6690.3573, 2985.1439],\n",
      "        [6694.7385, 2983.7306]], dtype=torch.float64), tensor([ 4., -1.], dtype=torch.float64)), (tensor([[7352.4084, 3223.0308],\n",
      "        [7355.4807, 3227.2092]], dtype=torch.float64), tensor([1., 3.], dtype=torch.float64)), (tensor([[8121.4437, 3721.3101],\n",
      "        [8122.7447, 3722.7039]], dtype=torch.float64), tensor([0., 2.], dtype=torch.float64)), (tensor([[6309.5258, 2858.5257],\n",
      "        [6313.2126, 2862.8270]], dtype=torch.float64), tensor([3., 3.], dtype=torch.float64)), (tensor([[5914.8256, 2572.8390],\n",
      "        [5917.2417, 2574.3258]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[4541.1952, 2457.6109],\n",
      "        [4541.8456, 2460.9563]], dtype=torch.float64), tensor([1., 1.], dtype=torch.float64)), (tensor([[7595.2479, 3412.5341],\n",
      "        [7599.3034, 3413.2714]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[8654.0020, 4009.9379],\n",
      "        [8657.4402, 4010.2166]], dtype=torch.float64), tensor([3., -0.], dtype=torch.float64)), (tensor([[5701.2819, 2466.9964],\n",
      "        [5705.9282, 2466.8106]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[8488.6908, 3940.7346],\n",
      "        [8492.6234, 3940.6117]], dtype=torch.float64), tensor([4., -0.], dtype=torch.float64)), (tensor([[5163.9845, 2422.2991],\n",
      "        [5169.9317, 2422.6708]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[7567.8424, 3402.5796],\n",
      "        [7570.6690, 3404.3001]], dtype=torch.float64), tensor([4., 2.], dtype=torch.float64)), (tensor([[8153.7819, 3763.4055],\n",
      "        [8154.9900, 3764.7064]], dtype=torch.float64), tensor([1., 1.], dtype=torch.float64)), (tensor([[5744.6783, 2482.3292],\n",
      "        [5746.0722, 2484.8382]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[4555.6916, 2472.6649],\n",
      "        [4558.2935, 2473.5013]], dtype=torch.float64), tensor([1., 1.], dtype=torch.float64)), (tensor([[8600.5696, 3985.0337],\n",
      "        [8601.6847, 3986.8922]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[7186.1321, 3125.2068],\n",
      "        [7189.4503, 3126.3128]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[7974.4350, 3683.7680],\n",
      "        [7978.3379, 3685.5336]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[5514.9655, 2442.3711],\n",
      "        [5519.8906, 2443.1145]], dtype=torch.float64), tensor([5., 1.], dtype=torch.float64)), (tensor([[4939.0109, 2422.2991],\n",
      "        [4941.8916, 2422.2991]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[7953.8983, 3681.5378],\n",
      "        [7957.3366, 3682.4670]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[7548.6709, 3387.0949],\n",
      "        [7551.4974, 3389.9215]], dtype=torch.float64), tensor([2., 3.], dtype=torch.float64)), (tensor([[8467.9216, 3941.3490],\n",
      "        [8473.0832, 3940.4888]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[6282.6119, 2836.0360],\n",
      "        [6286.4216, 2838.7397]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[6084.6289, 2690.4061],\n",
      "        [6089.0531, 2694.2158]], dtype=torch.float64), tensor([4., 3.], dtype=torch.float64)), (tensor([[6144.9700, 2729.7323],\n",
      "        [6149.2714, 2732.3131]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[4543.5183, 2463.6511],\n",
      "        [4545.1910, 2465.7884]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[4890.2248, 2425.9232],\n",
      "        [4893.9418, 2425.8303]], dtype=torch.float64), tensor([ 3., -1.], dtype=torch.float64)), (tensor([[5371.6738, 2431.7775],\n",
      "        [5377.6211, 2431.6846]], dtype=torch.float64), tensor([ 5., -1.], dtype=torch.float64)), (tensor([[4811.1449, 2449.8981],\n",
      "        [4814.7690, 2447.6679]], dtype=torch.float64), tensor([ 3., -1.], dtype=torch.float64)), (tensor([[8257.1155, 3842.4854],\n",
      "        [8257.8589, 3845.0873]], dtype=torch.float64), tensor([1., 3.], dtype=torch.float64)), (tensor([[5562.0790, 2447.4820],\n",
      "        [5566.3535, 2448.3183]], dtype=torch.float64), tensor([7., 1.], dtype=torch.float64)), (tensor([[7067.0474, 3063.0221],\n",
      "        [7071.4716, 3064.4969]], dtype=torch.float64), tensor([4., 2.], dtype=torch.float64)), (tensor([[8460.5479, 3941.2261],\n",
      "        [8464.7264, 3940.7346]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[4807.0561, 2452.3142],\n",
      "        [4811.1449, 2449.8981]], dtype=torch.float64), tensor([ 4., -2.], dtype=torch.float64)), (tensor([[7383.5007, 3268.6246],\n",
      "        [7387.8020, 3269.7307]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[8157.4990, 3767.4942],\n",
      "        [8159.0787, 3768.8881]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[5599.2493, 2456.7746],\n",
      "        [5605.4753, 2458.7260]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[4820.6233, 2443.9508],\n",
      "        [4824.2474, 2441.9065]], dtype=torch.float64), tensor([ 3., -2.], dtype=torch.float64)), (tensor([[8403.1950, 3934.4820],\n",
      "        [8405.3323, 3935.0396]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[4541.8456, 2460.9563],\n",
      "        [4542.6820, 2461.9784]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[6995.0312, 3017.7970],\n",
      "        [6997.6120, 3021.2380]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[4949.0469, 2421.9274],\n",
      "        [4950.3478, 2422.1132]], dtype=torch.float64), tensor([ 3., -1.], dtype=torch.float64)), (tensor([[7129.6007, 3104.1918],\n",
      "        [7132.6730, 3105.5436]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[5761.4050, 2494.4096],\n",
      "        [5764.7503, 2496.1752]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[8332.6643, 3899.5419],\n",
      "        [8335.7308, 3900.8429]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[5605.4753, 2458.7260],\n",
      "        [5609.0994, 2460.1199]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[7878.9314, 3625.7867],\n",
      "        [7881.0513, 3630.1679]], dtype=torch.float64), tensor([2., 3.], dtype=torch.float64)), (tensor([[5842.5293, 2499.7064],\n",
      "        [5846.5251, 2501.9366]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[4757.8054, 2486.5109],\n",
      "        [4761.1507, 2483.8160]], dtype=torch.float64), tensor([ 3., -3.], dtype=torch.float64)), (tensor([[8380.5211, 3924.7248],\n",
      "        [8382.1008, 3926.4904]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[5898.1919, 2515.1321],\n",
      "        [5896.6121, 2516.8047]], dtype=torch.float64), tensor([-1.,  2.], dtype=torch.float64)), (tensor([[7946.3714, 3678.7500],\n",
      "        [7949.9955, 3680.7014]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[4507.6328, 2528.6346],\n",
      "        [4508.6832, 2524.7559]], dtype=torch.float64), tensor([ 1., -3.], dtype=torch.float64)), (tensor([[8258.6953, 3848.1539],\n",
      "        [8259.1599, 3850.5700]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[8587.1883, 3965.7981],\n",
      "        [8588.7680, 3968.1212]], dtype=torch.float64), tensor([1., 3.], dtype=torch.float64)), (tensor([[6990.4841, 3013.1270],\n",
      "        [6992.6962, 3014.9704]], dtype=torch.float64), tensor([2., 3.], dtype=torch.float64)), (tensor([[5705.9282, 2466.8106],\n",
      "        [5711.4109, 2466.9964]], dtype=torch.float64), tensor([4., -0.], dtype=torch.float64)), (tensor([[5898.1919, 2513.1806],\n",
      "        [5898.1919, 2515.1321]], dtype=torch.float64), tensor([-2.,  2.], dtype=torch.float64)), (tensor([[4628.7313, 2500.7285],\n",
      "        [4630.3111, 2502.4012]], dtype=torch.float64), tensor([1., 3.], dtype=torch.float64)), (tensor([[4630.3111, 2502.4012],\n",
      "        [4631.2403, 2505.5607]], dtype=torch.float64), tensor([0., 2.], dtype=torch.float64)), (tensor([[6958.9002, 2982.0347],\n",
      "        [6960.6207, 2985.1070]], dtype=torch.float64), tensor([1., 3.], dtype=torch.float64)), (tensor([[6336.5626, 2888.5120],\n",
      "        [6340.8639, 2892.3217]], dtype=torch.float64), tensor([5., 4.], dtype=torch.float64)), (tensor([[6788.4394, 2977.9362],\n",
      "        [6791.9726, 2976.5229]], dtype=torch.float64), tensor([ 3., -1.], dtype=torch.float64)), (tensor([[6173.2358, 2744.2339],\n",
      "        [6177.6600, 2746.2002]], dtype=torch.float64), tensor([4., 2.], dtype=torch.float64)), (tensor([[5447.2226, 2433.8219],\n",
      "        [5451.7759, 2435.4946]], dtype=torch.float64), tensor([6., 2.], dtype=torch.float64)), (tensor([[8647.9618, 4009.8449],\n",
      "        [8650.9354, 4009.8449]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[4542.0315, 2445.9952],\n",
      "        [4541.4739, 2447.8537]], dtype=torch.float64), tensor([-0., 2.], dtype=torch.float64)), (tensor([[8645.0811, 4008.9157],\n",
      "        [8647.9618, 4009.8449]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[7901.6853, 3650.8019],\n",
      "        [7904.3705, 3652.6392]], dtype=torch.float64), tensor([4., 2.], dtype=torch.float64)), (tensor([[5566.3535, 2448.3183],\n",
      "        [5573.6018, 2449.6193]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[7747.8828, 3486.3937],\n",
      "        [7750.3407, 3487.3768]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[7620.4412, 3415.4835],\n",
      "        [7623.6365, 3415.4835]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[7684.4693, 3433.9177],\n",
      "        [7687.0500, 3434.5322]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[4742.0080, 2501.0073],\n",
      "        [4744.8887, 2498.2195]], dtype=torch.float64), tensor([ 3., -3.], dtype=torch.float64)), (tensor([[7750.3407, 3487.3768],\n",
      "        [7754.3962, 3487.7455]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[7084.0068, 3070.7645],\n",
      "        [7086.5876, 3072.3621]], dtype=torch.float64), tensor([2., 3.], dtype=torch.float64)), (tensor([[7239.3454, 3156.9135],\n",
      "        [7240.8202, 3159.1256]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[5396.3921, 2428.3393],\n",
      "        [5400.4808, 2426.9454]], dtype=torch.float64), tensor([ 4., -1.], dtype=torch.float64)), (tensor([[6992.6962, 3014.9704],\n",
      "        [6995.0312, 3017.7970]], dtype=torch.float64), tensor([3., 3.], dtype=torch.float64)), (tensor([[8120.7003, 3715.1770],\n",
      "        [8120.7003, 3718.0577]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[7916.6661, 3659.9883],\n",
      "        [7919.7753, 3661.8255]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[8065.8740, 3693.6181],\n",
      "        [8068.4760, 3694.5474]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[6547.9411, 2967.2873],\n",
      "        [6551.6279, 2968.7621]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[7692.7032, 3441.0456],\n",
      "        [7693.3177, 3443.1348]], dtype=torch.float64), tensor([1., 1.], dtype=torch.float64)), (tensor([[5890.2003, 2503.3305],\n",
      "        [5894.0102, 2502.2154]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[5387.6571, 2429.7332],\n",
      "        [5391.9317, 2428.9898]], dtype=torch.float64), tensor([ 4., -1.], dtype=torch.float64)), (tensor([[7304.3566, 3195.5024],\n",
      "        [7308.5350, 3197.1000]], dtype=torch.float64), tensor([6., 2.], dtype=torch.float64)), (tensor([[4595.5568, 2484.8382],\n",
      "        [4599.2738, 2485.4887]], dtype=torch.float64), tensor([5., 1.], dtype=torch.float64)), (tensor([[7108.3399, 3090.6734],\n",
      "        [7111.0436, 3093.1313]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[8214.9272, 3800.3900],\n",
      "        [8216.5069, 3801.6910]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[4790.5153, 2462.0714],\n",
      "        [4793.5819, 2459.8411]], dtype=torch.float64), tensor([ 3., -2.], dtype=torch.float64)), (tensor([[8314.4508, 3888.2979],\n",
      "        [8316.4022, 3889.9705]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[7733.1355, 3474.9645],\n",
      "        [7734.8560, 3476.9308]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[4985.8866, 2419.4458],\n",
      "        [4989.1891, 2419.5161]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[7015.9233, 3037.5830],\n",
      "        [7018.9956, 3039.1806]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[8353.7584, 3908.4628],\n",
      "        [8355.8957, 3909.8567]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[7505.5349, 3325.2790],\n",
      "        [7507.2554, 3326.2621]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[5464.6926, 2438.3753],\n",
      "        [5470.9187, 2439.5833]], dtype=torch.float64), tensor([6., 0.], dtype=torch.float64)), (tensor([[8227.4722, 3812.9350],\n",
      "        [8229.7953, 3815.6298]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[4632.5076, 2517.6164],\n",
      "        [4632.5076, 2524.8672]], dtype=torch.float64), tensor([-0., 6.], dtype=torch.float64)), (tensor([[4523.6322, 2456.4029],\n",
      "        [4524.2826, 2452.1283]], dtype=torch.float64), tensor([ 1., -2.], dtype=torch.float64)), (tensor([[7105.1447, 3088.5842],\n",
      "        [7108.3399, 3090.6734]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[4663.2998, 2553.9751],\n",
      "        [4668.2248, 2553.1387]], dtype=torch.float64), tensor([ 5., -1.], dtype=torch.float64)), (tensor([[4936.6877, 2422.3920],\n",
      "        [4939.0109, 2422.2991]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[7971.0896, 3683.3034],\n",
      "        [7974.4350, 3683.7680]], dtype=torch.float64), tensor([4., 2.], dtype=torch.float64)), (tensor([[7898.8587, 3648.8233],\n",
      "        [7901.6853, 3650.8019]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[6199.9039, 2758.8583],\n",
      "        [6203.5907, 2762.4222]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[6652.4014, 2982.7721],\n",
      "        [6655.5966, 2984.1239]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[5749.6963, 2488.6482],\n",
      "        [5751.1831, 2489.6704]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[5161.6613, 2422.2062],\n",
      "        [5163.9845, 2422.2991]], dtype=torch.float64), tensor([6., 0.], dtype=torch.float64)), (tensor([[5228.3821, 2425.8303],\n",
      "        [5231.9133, 2426.3878]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[8249.3097, 3832.4494],\n",
      "        [8251.1683, 3833.2858]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[6743.7796, 2980.0561],\n",
      "        [6749.1501, 2979.2081]], dtype=torch.float64), tensor([5., 1.], dtype=torch.float64)), (tensor([[7319.2269, 3200.5411],\n",
      "        [7322.9137, 3201.7700]], dtype=torch.float64), tensor([4., 2.], dtype=torch.float64)), (tensor([[8081.4856, 3697.0564],\n",
      "        [8084.4592, 3697.5210]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[8618.7831, 4000.5523],\n",
      "        [8621.2921, 4001.4816]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[8091.3357, 3700.4947],\n",
      "        [8093.8447, 3701.6098]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[7053.5290, 3057.8606],\n",
      "        [7056.6013, 3059.0895]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[5743.4703, 2480.0061],\n",
      "        [5744.6783, 2482.3292]], dtype=torch.float64), tensor([1., 3.], dtype=torch.float64)), (tensor([[4885.6714, 2426.0161],\n",
      "        [4890.2248, 2425.9232]], dtype=torch.float64), tensor([4., -0.], dtype=torch.float64)), (tensor([[4725.8389, 2514.6674],\n",
      "        [4727.5116, 2513.2735]], dtype=torch.float64), tensor([ 3., -3.], dtype=torch.float64)), (tensor([[5577.2259, 2450.7344],\n",
      "        [5582.1509, 2451.9424]], dtype=torch.float64), tensor([6., 1.], dtype=torch.float64)), (tensor([[7401.9348, 3270.4680],\n",
      "        [7406.7277, 3270.8367]], dtype=torch.float64), tensor([5., 1.], dtype=torch.float64)), (tensor([[6008.1885, 2614.7031],\n",
      "        [6011.5066, 2618.5128]], dtype=torch.float64), tensor([3., 3.], dtype=torch.float64)), (tensor([[7526.5499, 3356.6171],\n",
      "        [7528.1475, 3360.5497]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[6218.9525, 2778.2756],\n",
      "        [6221.7791, 2781.7167]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[7071.4716, 3064.4969],\n",
      "        [7075.4042, 3066.0945]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[4824.2474, 2441.9065],\n",
      "        [4827.4069, 2440.3267]], dtype=torch.float64), tensor([ 4., -1.], dtype=torch.float64)), (tensor([[4524.1170, 2506.0092],\n",
      "        [4526.3795, 2503.1810]], dtype=torch.float64), tensor([ 2., -4.], dtype=torch.float64)), (tensor([[6286.4216, 2838.7397],\n",
      "        [6289.6169, 2840.0916]], dtype=torch.float64), tensor([3., 3.], dtype=torch.float64)), (tensor([[6194.7423, 2754.9257],\n",
      "        [6197.5689, 2756.8920]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[6832.3189, 2976.2586],\n",
      "        [6836.7431, 2975.7671]], dtype=torch.float64), tensor([ 4., -1.], dtype=torch.float64)), (tensor([[4688.1110, 2544.0320],\n",
      "        [4691.0846, 2542.4523]], dtype=torch.float64), tensor([ 3., -1.], dtype=torch.float64)), (tensor([[7831.5863, 3543.5334],\n",
      "        [7833.1409, 3548.3386]], dtype=torch.float64), tensor([2., 4.], dtype=torch.float64)), (tensor([[7603.2360, 3414.1317],\n",
      "        [7607.9060, 3414.6233]], dtype=torch.float64), tensor([4., -0.], dtype=torch.float64)), (tensor([[5955.9918, 2583.9901],\n",
      "        [5960.8239, 2584.1760]], dtype=torch.float64), tensor([5., 1.], dtype=torch.float64)), (tensor([[4912.3412, 2424.3435],\n",
      "        [4915.3148, 2424.3435]], dtype=torch.float64), tensor([2., -0.], dtype=torch.float64)), (tensor([[6556.4208, 2968.8850],\n",
      "        [6561.0908, 2969.1308]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[5861.5791, 2507.9768],\n",
      "        [5865.6678, 2508.8131]], dtype=torch.float64), tensor([ 4., -1.], dtype=torch.float64)), (tensor([[7111.0436, 3093.1313],\n",
      "        [7114.1160, 3094.7289]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[4803.3391, 2454.0797],\n",
      "        [4807.0561, 2452.3142]], dtype=torch.float64), tensor([ 4., -2.], dtype=torch.float64)), (tensor([[5935.6410, 2580.4589],\n",
      "        [5941.6812, 2581.8528]], dtype=torch.float64), tensor([5., 1.], dtype=torch.float64)), (tensor([[7349.7047, 3219.8355],\n",
      "        [7352.4084, 3223.0308]], dtype=torch.float64), tensor([3., 4.], dtype=torch.float64)), (tensor([[4528.2785, 2475.9173],\n",
      "        [4526.6987, 2472.2003]], dtype=torch.float64), tensor([-1., -3.], dtype=torch.float64)), (tensor([[7961.9829, 3682.7458],\n",
      "        [7966.8150, 3682.9317]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[6703.9249, 2980.9041],\n",
      "        [6708.5887, 2981.6107]], dtype=torch.float64), tensor([5., 2.], dtype=torch.float64)), (tensor([[5796.9027, 2496.7327],\n",
      "        [5800.8056, 2495.9893]], dtype=torch.float64), tensor([ 5., -1.], dtype=torch.float64)), (tensor([[8257.8589, 3845.0873],\n",
      "        [8258.6953, 3848.1539]], dtype=torch.float64), tensor([0., 2.], dtype=torch.float64)), (tensor([[7473.5823, 3300.7001],\n",
      "        [7477.5150, 3303.8953]], dtype=torch.float64), tensor([3., 3.], dtype=torch.float64)), (tensor([[5869.2919, 2508.0697],\n",
      "        [5873.7524, 2507.6051]], dtype=torch.float64), tensor([ 5., -1.], dtype=torch.float64)), (tensor([[5854.9813, 2505.7465],\n",
      "        [5857.9550, 2506.8616]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[7249.0541, 3167.9740],\n",
      "        [7251.7578, 3171.0464]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[8279.8824, 3865.8098],\n",
      "        [8281.7409, 3867.2966]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[4625.7577, 2496.0822],\n",
      "        [4627.6162, 2498.6842]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[5920.4941, 2575.9056],\n",
      "        [5924.3970, 2577.6712]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[6496.0796, 2958.5618],\n",
      "        [6499.7664, 2958.4389]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[4761.1507, 2483.8160],\n",
      "        [4764.5890, 2481.1212]], dtype=torch.float64), tensor([ 4., -3.], dtype=torch.float64)), (tensor([[4841.9033, 2435.5875],\n",
      "        [4845.2487, 2434.4724]], dtype=torch.float64), tensor([ 3., -1.], dtype=torch.float64)), (tensor([[7881.0513, 3630.1679],\n",
      "        [7883.4539, 3633.4185]], dtype=torch.float64), tensor([3., 3.], dtype=torch.float64)), (tensor([[6655.5966, 2984.1239],\n",
      "        [6658.6997, 2984.4373]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[6442.3747, 2958.5618],\n",
      "        [6445.5700, 2959.4221]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[5740.1249, 2458.6331],\n",
      "        [5740.1249, 2460.9563]], dtype=torch.float64), tensor([1., 3.], dtype=torch.float64)), (tensor([[8253.4914, 3837.1886],\n",
      "        [8254.7924, 3838.4896]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[7146.1914, 3112.0570],\n",
      "        [7149.3867, 3113.0402]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[7696.1442, 3449.7711],\n",
      "        [7697.0045, 3451.6145]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[5899.2141, 2511.6938],\n",
      "        [5898.1919, 2513.1806]], dtype=torch.float64), tensor([0., 2.], dtype=torch.float64)), (tensor([[8193.6471, 3788.5884],\n",
      "        [8195.9703, 3789.4247]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[6675.2352, 2987.5465],\n",
      "        [6680.4643, 2986.5572]], dtype=torch.float64), tensor([ 5., -1.], dtype=torch.float64)), (tensor([[7344.9118, 3214.6739],\n",
      "        [7347.1239, 3217.1318]], dtype=torch.float64), tensor([3., 3.], dtype=torch.float64)), (tensor([[7694.9153, 3447.3132],\n",
      "        [7696.1442, 3449.7711]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[6929.0369, 2980.5599],\n",
      "        [6933.5840, 2980.1913]], dtype=torch.float64), tensor([ 5., -1.], dtype=torch.float64)), (tensor([[8074.8879, 3695.6625],\n",
      "        [8077.8615, 3696.3130]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[7789.5441, 3489.7118],\n",
      "        [7793.8515, 3490.3939]], dtype=torch.float64), tensor([5., 2.], dtype=torch.float64)), (tensor([[8113.1733, 3704.4905],\n",
      "        [8115.5894, 3704.5834]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[5647.1991, 2473.1295],\n",
      "        [5650.2656, 2474.5234]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[5078.3068, 2420.3476],\n",
      "        [5081.9309, 2420.2547]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[7363.2231, 3249.6989],\n",
      "        [7364.8207, 3253.3857]], dtype=torch.float64), tensor([2., 5.], dtype=torch.float64)), (tensor([[6197.5689, 2756.8920],\n",
      "        [6199.9039, 2758.8583]], dtype=torch.float64), tensor([4., 4.], dtype=torch.float64)), (tensor([[6071.1105, 2678.3624],\n",
      "        [6077.2552, 2684.2613]], dtype=torch.float64), tensor([7., 6.], dtype=torch.float64)), (tensor([[7330.2874, 3204.8424],\n",
      "        [7335.0802, 3207.1774]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[7719.4942, 3467.7137],\n",
      "        [7722.0750, 3468.9426]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[6313.2126, 2862.8270],\n",
      "        [6316.6536, 2866.0223]], dtype=torch.float64), tensor([2., 3.], dtype=torch.float64)), (tensor([[8180.0800, 3782.3624],\n",
      "        [8182.4960, 3783.2916]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[5788.9110, 2497.9408],\n",
      "        [5792.6281, 2497.4761]], dtype=torch.float64), tensor([ 4., -1.], dtype=torch.float64)), (tensor([[4772.8594, 2474.9881],\n",
      "        [4775.2755, 2472.9437]], dtype=torch.float64), tensor([ 3., -3.], dtype=torch.float64)), (tensor([[6098.8846, 2701.0979],\n",
      "        [6103.9233, 2704.0474]], dtype=torch.float64), tensor([6., 4.], dtype=torch.float64)), (tensor([[6634.8275, 2976.3815],\n",
      "        [6637.5311, 2977.4876]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[7587.6284, 3411.0593],\n",
      "        [7591.1924, 3412.0425]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[7772.5846, 3488.8515],\n",
      "        [7775.9028, 3488.8515]], dtype=torch.float64), tensor([4., 0.], dtype=torch.float64)), (tensor([[8068.4760, 3694.5474],\n",
      "        [8071.3567, 3694.8262]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[8507.2478, 3940.4888],\n",
      "        [8512.2865, 3940.2430]], dtype=torch.float64), tensor([5., 1.], dtype=torch.float64)), (tensor([[5074.2180, 2421.2769],\n",
      "        [5078.3068, 2420.3476]], dtype=torch.float64), tensor([4., -0.], dtype=torch.float64)), (tensor([[7834.4128, 3513.7131],\n",
      "        [7835.8261, 3515.5504]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[8120.2357, 3707.2783],\n",
      "        [8120.5145, 3709.5085]], dtype=torch.float64), tensor([0., 2.], dtype=torch.float64)), (tensor([[4492.6838, 2547.2198],\n",
      "        [4497.4513, 2544.3916]], dtype=torch.float64), tensor([ 3., -3.], dtype=torch.float64)), (tensor([[8608.4683, 3993.3971],\n",
      "        [8610.6985, 3995.2556]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[8584.1217, 3960.7801],\n",
      "        [8585.4227, 3963.5678]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[7834.8368, 3552.0132],\n",
      "        [7836.6741, 3555.5464]], dtype=torch.float64), tensor([3., 5.], dtype=torch.float64)), (tensor([[6537.0035, 2964.3379],\n",
      "        [6541.5506, 2966.1813]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[4708.3688, 2529.4426],\n",
      "        [4710.6920, 2527.3053]], dtype=torch.float64), tensor([ 3., -3.], dtype=torch.float64)), (tensor([[6534.0540, 2963.6005],\n",
      "        [6537.0035, 2964.3379]], dtype=torch.float64), tensor([5., 2.], dtype=torch.float64)), (tensor([[4962.6991, 2420.4295],\n",
      "        [4967.6879, 2420.2187]], dtype=torch.float64), tensor([4., -0.], dtype=torch.float64)), (tensor([[6808.3668, 2974.2616],\n",
      "        [6813.4546, 2975.5336]], dtype=torch.float64), tensor([6., 1.], dtype=torch.float64)), (tensor([[6438.3192, 2958.1932],\n",
      "        [6442.3747, 2958.5618]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[6152.4666, 2733.6649],\n",
      "        [6156.3992, 2735.9999]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[8023.1281, 3692.5960],\n",
      "        [8026.5664, 3692.5960]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[5008.3013, 2420.7808],\n",
      "        [5011.8848, 2420.7106]], dtype=torch.float64), tensor([4., -0.], dtype=torch.float64)), (tensor([[6177.6600, 2746.2002],\n",
      "        [6181.8384, 2748.0436]], dtype=torch.float64), tensor([4., 3.], dtype=torch.float64)), (tensor([[5697.8437, 2468.2045],\n",
      "        [5701.2819, 2466.9964]], dtype=torch.float64), tensor([5., -0.], dtype=torch.float64)), (tensor([[8254.7924, 3838.4896],\n",
      "        [8256.0004, 3840.4410]], dtype=torch.float64), tensor([1., 2.], dtype=torch.float64)), (tensor([[7775.9028, 3488.8515],\n",
      "        [7779.4667, 3488.8515]], dtype=torch.float64), tensor([3., 0.], dtype=torch.float64)), (tensor([[6551.6279, 2968.7621],\n",
      "        [6556.4208, 2968.8850]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[4482.6640, 2550.9368],\n",
      "        [4488.6435, 2548.7551]], dtype=torch.float64), tensor([ 4., -2.], dtype=torch.float64)), (tensor([[7668.7388, 3428.8790],\n",
      "        [7673.2859, 3430.1080]], dtype=torch.float64), tensor([5., 2.], dtype=torch.float64)), (tensor([[5391.9317, 2428.9898],\n",
      "        [5396.3921, 2428.3393]], dtype=torch.float64), tensor([ 4., -1.], dtype=torch.float64)), (tensor([[8263.7133, 3856.0526],\n",
      "        [8265.9435, 3858.0040]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[8297.7241, 3874.6378],\n",
      "        [8300.1402, 3875.9387]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[6231.6107, 2793.2688],\n",
      "        [6235.0517, 2796.8327]], dtype=torch.float64), tensor([3., 4.], dtype=torch.float64)), (tensor([[8439.5330, 3940.7346],\n",
      "        [8444.3259, 3941.1032]], dtype=torch.float64), tensor([6., 0.], dtype=torch.float64)), (tensor([[4544.1688, 2433.0785],\n",
      "        [4544.3546, 2435.6804]], dtype=torch.float64), tensor([-0., 2.], dtype=torch.float64)), (tensor([[7242.0491, 3161.2148],\n",
      "        [7244.6299, 3164.0414]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[7925.4285, 3665.5001],\n",
      "        [7928.9617, 3667.6200]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[5977.5878, 2588.5265],\n",
      "        [5981.6433, 2591.4760]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[7040.2564, 3051.9616],\n",
      "        [7043.0829, 3053.6822]], dtype=torch.float64), tensor([4., 2.], dtype=torch.float64)), (tensor([[4466.9749, 2554.5155],\n",
      "        [4471.7801, 2553.3849]], dtype=torch.float64), tensor([ 6., -1.], dtype=torch.float64)), (tensor([[5909.8076, 2568.5644],\n",
      "        [5912.3166, 2570.7017]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[7135.9912, 3107.5100],\n",
      "        [7139.0635, 3109.5992]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[8295.7727, 3873.5227],\n",
      "        [8297.7241, 3874.6378]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[6321.0778, 2872.7815],\n",
      "        [6323.9044, 2875.4852]], dtype=torch.float64), tensor([2., 2.], dtype=torch.float64)), (tensor([[8204.3336, 3793.4205],\n",
      "        [8205.9134, 3794.4427]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[5895.0324, 2526.5619],\n",
      "        [5895.4041, 2528.6992]], dtype=torch.float64), tensor([0., 3.], dtype=torch.float64)), (tensor([[6422.3429, 2951.6797],\n",
      "        [6426.8900, 2954.0147]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[8190.9523, 3787.7521],\n",
      "        [8193.6471, 3788.5884]], dtype=torch.float64), tensor([2., 1.], dtype=torch.float64)), (tensor([[7218.0847, 3130.4912],\n",
      "        [7222.8776, 3129.5081]], dtype=torch.float64), tensor([3., -0.], dtype=torch.float64)), (tensor([[5757.4092, 2492.9228],\n",
      "        [5761.4050, 2494.4096]], dtype=torch.float64), tensor([3., 2.], dtype=torch.float64)), (tensor([[7366.4183, 3258.0557],\n",
      "        [7368.8762, 3262.1112]], dtype=torch.float64), tensor([3., 3.], dtype=torch.float64)), (tensor([[5020.1058, 2420.6403],\n",
      "        [5023.0159, 2420.4406]], dtype=torch.float64), tensor([3., 1.], dtype=torch.float64)), (tensor([[6645.0277, 2980.0684],\n",
      "        [6648.4688, 2981.9118]], dtype=torch.float64), tensor([4., 1.], dtype=torch.float64)), (tensor([[4727.5116, 2513.2735],\n",
      "        [4730.4852, 2510.7645]], dtype=torch.float64), tensor([ 3., -2.], dtype=torch.float64)), (tensor([[8496.8018, 3940.3659],\n",
      "        [8501.9634, 3940.4888]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64)), (tensor([[8664.7814, 4010.9600],\n",
      "        [8667.4762, 4011.9822]], dtype=torch.float64), tensor([2., -0.], dtype=torch.float64)), (tensor([[7397.3877, 3269.8536],\n",
      "        [7401.9348, 3270.4680]], dtype=torch.float64), tensor([5., 0.], dtype=torch.float64))]\n",
      "Subset\n",
      "|__tuple\n",
      "  |__Tensor (dtype: torch.float64)\n",
      "  | |__Tensor (dtype: torch.float64)\n",
      "  |   |__Tensor (dtype: torch.float64)\n",
      "  |__Tensor (dtype: torch.float64)\n",
      "    |__Tensor (dtype: torch.float64)\n",
      "      |__Tensor (dtype: torch.float64)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "image = get_padded_image(\"./juneau2k.jpg\")\n",
    "train_data, test_data = get_line_data(0)\n",
    "print(list(test_data))\n",
    "print(typeTree(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_line_data(0)\n",
    "train, test = d[0], d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n",
      "|__Subset\n",
      "| |__tuple\n",
      "|   |__Tensor (dtype: torch.float64)\n",
      "|   | |__Tensor (dtype: torch.float64)\n",
      "|   |   |__Tensor (dtype: torch.float64)\n",
      "|   |__Tensor (dtype: torch.float64)\n",
      "|     |__Tensor (dtype: torch.float64)\n",
      "|       |__Tensor (dtype: torch.float64)\n",
      "|__Subset\n",
      "  |__tuple\n",
      "    |__Tensor (dtype: torch.float64)\n",
      "    | |__Tensor (dtype: torch.float64)\n",
      "    |   |__Tensor (dtype: torch.float64)\n",
      "    |__Tensor (dtype: torch.float64)\n",
      "      |__Tensor (dtype: torch.float64)\n",
      "        |__Tensor (dtype: torch.float64)\n"
     ]
    }
   ],
   "source": [
    "typeTree(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m current_location \u001b[39m=\u001b[39m extract_patch(image, data[\u001b[39m1\u001b[39m], size)\n\u001b[1;32m      6\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([previous_location, current_location])\n\u001b[0;32m----> 7\u001b[0m prediction \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(prediction, target)\n\u001b[1;32m      9\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/LineWalker/model.py:120\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    119\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(x)\n\u001b[0;32m--> 120\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpositional_encoding(x)\n\u001b[1;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder_layers:\n\u001b[1;32m    123\u001b[0m         x \u001b[39m=\u001b[39m layer(x, x, mask\u001b[39m=\u001b[39mmask)  \u001b[39m# For GPT, the input and memory are the same\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/LineWalker/model.py:31\u001b[0m, in \u001b[0;36mPositionalEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 31\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpe[:, : x\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39m)]\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "size = 9\n",
    "for batch_idx, (data, target) in enumerate(list(train)[:10]):\n",
    "    optimizer.zero_grad()\n",
    "    previous_location = extract_patch(image, data[0], size)\n",
    "    current_location = extract_patch(image, data[1], size)\n",
    "    input = torch.stack([previous_location, current_location])\n",
    "    prediction = model(input)\n",
    "    loss = loss_fn(prediction, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc, recursive type displayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeTree(thing, indent=0, seen=None, active_branches=None, is_last_child=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    if active_branches is None:\n",
    "        active_branches = []\n",
    "    if is_last_child is None:\n",
    "        is_last_child = []\n",
    "\n",
    "    current_type = type(thing).__name__\n",
    "\n",
    "    # Create the prefix string using vertical and horizontal bars\n",
    "    prefix = \"\".join(\n",
    "        \"| \" if active and not last else \"  \"\n",
    "        for active, last in zip(active_branches[:-1], is_last_child[:-1])\n",
    "    )\n",
    "    prefix += \"|__\" if active_branches else \"\"\n",
    "\n",
    "    dtype_str = \"\"\n",
    "    if hasattr(thing, \"dtype\"):\n",
    "        dtype_str = f\" (dtype: {thing.dtype})\"\n",
    "\n",
    "    if current_type not in seen:\n",
    "        print(f\"{prefix}{current_type}{dtype_str}\")\n",
    "        seen.add(current_type)\n",
    "\n",
    "    if isinstance(thing, (list, tuple)):\n",
    "        local_seen = set()\n",
    "        for idx, item in enumerate(thing):\n",
    "            item_type = type(item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                new_is_last_child = is_last_child + [idx == len(thing) - 1]\n",
    "                new_active_branches = active_branches + [True]\n",
    "                typeTree(\n",
    "                    item, indent + 2, local_seen, new_active_branches, new_is_last_child\n",
    "                )\n",
    "                local_seen.add(item_type)\n",
    "\n",
    "    if hasattr(thing, \"__getitem__\"):\n",
    "        local_seen = set()\n",
    "        try:\n",
    "            sample_item = thing[0]\n",
    "        except (IndexError, KeyError, TypeError):\n",
    "            sample_item = None\n",
    "\n",
    "        if sample_item is not None:\n",
    "            item_type = type(sample_item).__name__\n",
    "            if item_type not in local_seen:\n",
    "                # Add a new active branch for the child node\n",
    "                new_active_branches = active_branches + [True]\n",
    "                new_is_last_child = is_last_child + [\n",
    "                    True\n",
    "                ]  # Assuming single item for now\n",
    "                typeTree(\n",
    "                    sample_item,\n",
    "                    indent + 2,\n",
    "                    local_seen,\n",
    "                    new_active_branches,\n",
    "                    new_is_last_child,\n",
    "                )\n",
    "                local_seen.add(item_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
